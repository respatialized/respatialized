✳ (ns respatialized.writing.intellectual-strip-mining) 🔚

✳(def metadata {:title "Intellectual strip mining"})  🔚

✳= [:h1 (:title metadata)] 🔚 

In understanding the current AI boom, I think it is worth examining a common cliche with a bit more of an eye to its historical context. If this  ✳= [:a {:href "https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications"} "chart from Andressen Horowitz"] 🔚 is any indication, in the AI gold rush, a lot more people are going to get rich selling the shovels of "LLMops" than by panning for gold in the streams of grammatical nonsense generated by language models.

Usually the historical analogy stops there, but it is worth remembering that when the naturally occurring rivers in the northern California landscape proved insufficient to the task of dissolving enough soil to find the gold sought by prospectors, they turned to more destructive means.


✳= [:figure
  [:img {:src "/media/1093px-Henry_Sandham_-_The_Monitor.jpeg"}]] 🔚
  

Whole hillsides were ripped away by ✳= [:a {:href "https://www.kcet.org/shows/earth-focus/mercury-in-our-waters-the-10-000-year-legacy-of-californias-gold-rush"} "hydraulic mining"] 🔚 in the search for gold, leading to toxic runoff that persists to this day, the destruction an incredibly rich ecosystem, and mass death for the tribal communities that lived there before the gold rush.

An electronic equivalent to ecosystem collapse may occur as the output of language and image generation models begins to pollute the environment being drawn from for the purposes of training data. 


✳= [:figure
  [:img {:src "/media/curse-of-recursion.jpg"}]] 🔚
  

Web-based intellectual ecosystems have been undergoing collapse for some time prior to the widespread use of large language models like ChatGPT.


Trivially-deployable bots overwhelm the human users of Q&A sites (https://github.com/RanjithJames/Reddit---Quora-question-BOT)
Estimates suggest about 1 in 3 website visitors is an attack bot (https://www.theatlantic.com/technology/archive/2017/01/bots-bots-bots/515043/)
Content mills drown out useful information in search results (https://www.technologyreview.com/2010/07/26/26327/the-search-engine-backlash-against-content-mills/)

All of those articles were written well before ChatGPT came on to the scene; language models did not create this trend, but they will certainly accelerate it. Efforts to thwart wholesale data harvesting on Twitter have been met with equally heavy-handed responses like blocking rate-limiting and requiring logins merely to view tweets - both of which attack the very foundations of the open internet. Those who thought that their Twitter feed would be a simple and public way of sharing their updates with the world have now found their reach limited to other Twitter users, and those like myself who have resisted the shrill siren song of the bird website are frozen out. OpenAI, as the first mover, very likely already has their hands on a large historical archive of Twitter data; it is everyone else who must pay the price.

Rob Horning writes:
✳= [:blockquote "LLMs are an innovation that reprivatizes public space. It creatively destroys the organization of information that the internet had once facilitated, back before it had come to depend on the environment of manipulation and deceit that characterizes advertising. “AI” indexes information without requiring social interaction, without any people organizing it with the needs of other people in mind. AI gets around having to have a “useful internet” that structures ways for people to develop trust in one another and the information they provide on an ongoing basis, beyond the kinds of branding and inculcation developed to support consumerism. It presents information with apparent directness, without the social mediation that contextualizes it; it organizes information as though it is all equally valid, no matter what purpose it originally served. It makes it seem as though all information has never been any better and any worse than advertising."] 🔚

