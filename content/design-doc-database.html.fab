âœ³(ns respatialized.writing.design.database
(:require [respatialized.render :refer :all]
[site.fabricate.prototype.page :refer :all]))ðŸ”š

âœ³(def metadata {:title "database design notes"})ðŸ”š

âœ³=[:header
[:h1 (:title metadata)]
[:h4 [:time {:datetime "2021-08-07 15:28"} "2021-08-07"]]]ðŸ”š

âœ³=[:figure [:blockquote "The work of art may be regarded as a machine programmed by the artist to produce a deferred output. Its objective is survivalâ€” by survival I mean not continued acclamation but a continued ability to stand intact as the organized system that the artist originally intended."]
[:figcaption "Jonathan Benthall, on the work of cybernetic sculptor Wen-Ying Tsai"]]ðŸ”š

âœ³=[:h2 "Goal 1: Reduce superfluous computation"]ðŸ”š

The simplest way to achieve this is to store a file hash and avoid re-rendering unchanged files.

A more sophisticated way of doing this, that allows for more granularity in what gets persisted and recomputed, would be to "memoize" certain expressions, storing their input arguments and outputs in the database so they can be re-used.


âœ³=[:h2 "Goal 2: Be fully reconstructible"]ðŸ”š

The second goal, in tension with the first, is that the database should not be the "source of truth" for the static site. The history of pages can be rebuilt from Git, should the database file ever get corrupted.

âœ³=[:h4 "What about things that don't need to be saved as individual files, like small SVG glyphs?"]ðŸ”š

Git can still be the source of truth for those, I believe, if âœ³=[:a {:href "https://git-scm.com/book/en/v2/Git-Internals-Git-Objects"} [:code "git hash-object"]]ðŸ”š is used correctly.


âœ³=[:h2 "Goal 3: Grant the author leverage"]ðŸ”š

âœ³=[:em "See: " [:a {:href "/not-a-tree.html"} "Structur and Alpha"] ", the writing tools employed by John McPhee for his books, implemented as extensions for Kedit"]ðŸ”š

If a database is to have broader use beyond just speeding up the page generation process, it needs to become part of the writing experience.

It should permit queries like "show me every quotation appearing in one of my writings, organized by the page it appears on." Most static website generators are unambitious in this regard, embracing a 1:1 model of "input file" â†’ "output page" that makes seeing âœ³=[:em "across"]ðŸ”š writing difficult or impossible beyond your basic browser control+F.

The database, in short, should support the creation and maintenance of the "organized system" that digital writing and generative art is so often âœ³=[:em "not"]ðŸ”š a part of.


âœ³=[:h2 "Concept: Reconstructing history"]ðŸ”š

Where goals 2 and 3 intersect is where things get really tricky. If the database becomes corrupted, how can it be reconstructed without repeatedly re-evalutating every revision of every file? The queries depend upon some state of the world that may not exist anymore, and is potentially expensive to recompute.

For one thing, that may not actually be a problem if the pages can be re-evaluated asynchronously. The object hash provided by git already also gives a deduplication mechanism if used intelligently.

âœ³=[:pre [:code "(query! all-quotes-query)"]]ðŸ”š
This query would need to capture its revision hash at time of execution for reproducibility. If a query tries to reach a commit not in the DB, that revision can be checked out and re-evaluated.

âœ³=[:h4 "One way of implementing this: " [:code "konserve-git"]]ðŸ”š

The general idea is that git would still handle all the plumbing and Datahike would be a kind of cache or porcelain atop it, giving users Clojure and fabricate-specific query capabilities. Might be unfeasible for performance reasons, as content-addressed files accessed through git may not be fast enough for real queries (counterexample: sqlite). Evaluated pages/forms could be stored directly in git using write-object, providing the caching mechanism for results.

âœ³=[:aside "prior art: " [:a {:href "https://github.com/Datomic/codeq"}[:code "codeq"]]]ðŸ”š
