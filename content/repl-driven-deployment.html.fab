âœ³(ns respatialized.writing.repl-driven-deployment)ðŸ”š

I've wondered for a while now about the "open" vs "closed" question in the context of deployments and systems.

The "traditional" way to do deployments is very artifact-centric - compile the jar, throw it on to a VM or Docker container and then perform some kind of controlled restart of the system in order to make changes to the code. The idea is that the code to execute is "closed" - this machine doesn't execute any code except what I tell it to.

However, one could imagine an alternate scenario where you just literally build your system out of a bunch of REPLs. VMs running continuously with a channel open to a trusted source hidden from the public internet (for the sake of argument I'm handwaving away security concerns/PLOP/etc) to receive new forms to evaluate. When you're ready to release your code, just redefine it. You may still need some kind of mount/component based system in order to ensure graceful termination of stateful resources when new forms come in on the wire, but I don't think there's anything in principle that prevents this kind of approach.

Beyond the ease-of-deployment aspect, you also get the benefit of a running REPL that can execute whatever code other things interacting with the system need to. Again, you may need to take care with sensitive resources like databases and such. However, the idea of a system that can be recomposed at runtime into combinations of components that weren't even necessarily foreseen at compile time is extremely intriguing to me. It seems like it would make the idea of an "API" more or less obsolete, because instead of making calls to a "closed" collection of defined endpoints, you can be "open" and just... execute some code, which is sent on the wire... as data. A runtime-recomposable system like this could save tons of design and architectural work by just giving its users a simple collection of primitive capabilities of the production system and letting users compose them, Unix style, in a more expressive language than Bash.

If you want to forbid some dangerous functions like shelling out, opening an untrusted connection, or whatever, you might build a detection mechanism that filters dangerous stuff out (and maybe even terminates the connection that the suspicious stuff came in from) and make sure to log every function sent in and called by these production REPLs. Not saying it wouldn't take work to ensure the security/stability of such a system, but in a trusted environment it could be extremely powerful. Plus, is it really that much worse than shipping around an entire Unix system with every app, just waiting for an attacker to shell out to?

Imagining scenarios like this is where I get kinda envious of Erlang-based systems, which seem leagues ahead of anything else when it comes to controlled redeploys and maintaining the liveness of the system. Joe Armstrong described what he called a "universal server" which I think inspired a lot of this. Fred Hebert has a great writeup on doing this kind of REPL based deployment and how Kubernetes falls way short of where Erlang has been for decades.
